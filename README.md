# LLM
这是AI派第二轮的面试题目，包含我对Llama技术报告的思考与理解\n
1.标准的多头注意力中每个头都有独立的Key和Value参数，而GQA是通过让query共享同一组k-v参数，减少k-v的数量来减少计算运行时的缓存所占用的内存，并且保证了每个q之间的独立性，这样做的好处就是能提高运算速度。\n
2.Llama3设计了一套自己的缩放定律（scaling laws）来确定旗舰模型的尺寸，首先建立了计算最优模型在下游任务上的负对数似然比与FLOP之间的关系。
